from typing import List, Tuple, Dict, Any
import numpy as np
import torch
import cv2
from PIL import Image
from exif import Image as ExifImage
from sklearn.cluster import DBSCAN
from haversine import haversine
import folium
from datetime import datetime
import os
import tensorflow as tf
import tensorflow_hub as hub
import geopy
from geopy.geocoders import Nominatim
import logging
import pytesseract

# Set Tesseract executable path 
pytesseract.pytesseract.tesseract_cmd = r'C:\Program Files\Tesseract-OCR\tesseract.exe'

# Initialize model variables
scene_model = None
midas = None
transform = None

def preprocess_image_for_ocr(image_path: str) -> str:
    """Preprocess image for better OCR results."""
    img = cv2.imread(image_path)
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    gray = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]
    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))
    gray = cv2.dilate(gray, kernel, iterations=1)
    temp_path = "temp_processed.png"
    cv2.imwrite(temp_path, gray)
    return temp_path

def detect_location_from_text(image_path: str) -> Tuple[float, float, float, str]:
    """Extract location information from text in the image."""
    try:
        # Preprocess image for better OCR
        processed_image = preprocess_image_for_ocr(image_path)
        img = Image.open(processed_image)
        
        # Perform OCR with custom configuration
        custom_config = r'--oem 3 --psm 6 -c preserve_interword_spaces=1'
        text = pytesseract.image_to_string(img, config=custom_config)
        
        # Clean up temporary file
        os.remove(processed_image)
        
        # Look for coordinates in the text
        coordinates_found = False
        lat = lon = None
        location_text = ""
        confidence = 0.0
        
        # Process each line of text
        lines = text.split('\n')
        for line in lines:
            # Look for latitude/longitude format
            if 'lat' in line.lower() and 'long' in line.lower():
                import re
                coords = re.findall(r'[-+]?\d*\.\d+|\d+', line)
                if len(coords) >= 2:
                    lat = float(coords[0])
                    lon = float(coords[1])
                    coordinates_found = True
                    confidence = 0.9  # High confidence for direct coordinate matches
                    
            # Look for address information
            elif any(keyword in line.lower() for keyword in ['street', 'road', 'avenue', 'building', 'city', 'state', 'pin']):
                location_text = line
                # Use geopy to convert address to coordinates if no direct coordinates found
                if not coordinates_found:
                    try:
                        geolocator = Nominatim(user_agent="board_verification")
                        location = geolocator.geocode(line)
                        if location:
                            lat = location.latitude
                            lon = location.longitude
                            coordinates_found = True
                            confidence = 0.7  # Lower confidence for geocoded addresses
                    except Exception as e:
                        print(f"Geocoding error: {e}")
        
        return lat, lon, confidence, location_text
        
    except Exception as e:
        print(f"OCR processing error: {e}")
        return None, None, 0.0, ""

def init_scene_model():
    """Initialize scene recognition model lazily on first use"""
    global scene_model
    if scene_model is None:
        try:
            # Load EfficientNet model for scene recognition
            model_url = "https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_b0/feature_vector/2"
            base_model = hub.KerasLayer(model_url, trainable=False)
            scene_model = tf.keras.Sequential([
                tf.keras.layers.InputLayer(input_shape=(224, 224, 3)),
                base_model,
                tf.keras.layers.Dense(1024, activation='relu'),
                tf.keras.layers.Dense(512, activation='relu'),
                tf.keras.layers.Dense(2, activation='linear')  # lat, lon prediction
            ])
        except Exception as e:
            logging.error(f"Error loading location detection model: {e}")
            raise

def analyze_image_authenticity(image_path: str) -> Tuple[float, List[str]]:
    """Analyze image for signs of manipulation."""
    try:
        img = cv2.imread(image_path)
        authenticity_score = 1.0
        reasons = []
        
        # Check 1: Error Level Analysis (ELA)
        temp_path = "temp_ela.jpg"
        cv2.imwrite(temp_path, img, [cv2.IMWRITE_JPEG_QUALITY, 90])
        ela_img = cv2.imread(temp_path)
        os.remove(temp_path)
        
        diff = cv2.absdiff(img, ela_img)
        ela_score = np.mean(diff)
        if ela_score > 50:  # Threshold determined empirically
            authenticity_score *= 0.7
            reasons.append("High error level analysis score suggests possible manipulation")
        
        # Check 2: Metadata consistency
        img_pil = Image.open(image_path)
        exif = img_pil._getexif() if hasattr(img_pil, '_getexif') else None
        if not exif:
            authenticity_score *= 0.9
            reasons.append("No EXIF metadata found")
        
        # Check 3: Image quality and noise analysis 
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        noise_score = cv2.Laplacian(gray, cv2.CV_64F).var()
        if noise_score < 100:  # Very low noise might indicate artificial images
            authenticity_score *= 0.8
            reasons.append("Unusually low image noise levels detected")
        
        return authenticity_score, reasons
        
    except Exception as e:
        print(f"Image authenticity analysis error: {e}")
        return 0.5, ["Error during authenticity analysis"]
        
    except Exception as e:
        print(f"Image authenticity analysis error: {e}")
        return 0.5, ["Error during authenticity analysis"]



def compute_depth(image_path: str):
    """Estimate camera-to-board distance using MiDaS."""
    try:
        # Initialize model if needed
        if midas is None:
            init_midas()
            
        img = cv2.imread(image_path)
        if img is None:
            raise ValueError("Unable to read image")
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        img = cv2.resize(img, (384, 384))
        input_batch = transform(img).to('cpu')
        with torch.no_grad():
            depth = midas(input_batch)
            depth = torch.nn.functional.interpolate(
                depth.unsqueeze(1), size=img.shape[:2], mode="bicubic",
                align_corners=False
            ).squeeze()
        return float(depth.mean().item())
    except Exception as e:
        print(f"Error computing depth: {str(e)}")
        return 0.0  # Safe default depth

def extract_exif_metadata(image_path: str):
    """Extract geolocation, timestamp, and device from EXIF."""
    try:
        with open(image_path, "rb") as img_file:
            img = ExifImage(img_file)
            lat = img.get("gps_latitude", None)
            lon = img.get("gps_longitude", None)
            timestamp = img.get("datetime", None)
            device = img.get("model", None)
            if lat and lon:
                lat = float(lat[0]) + lat[1]/60 + lat[2]/3600
                lon = float(lon[0]) + lon[1]/60 + lon[2]/3600
            if timestamp:
                timestamp = datetime.strptime(timestamp, "%Y:%m:%d %H:%M:%S")
            return {"lat": lat, "lon": lon, "timestamp": timestamp, "device": device}
    except:
        return {"lat": None, "lon": None, "timestamp": None, "device": None}

def cluster_geolocations(locations: List[tuple]):
    """Cluster geolocations using DBSCAN."""
    if not locations:
        return []
    db = DBSCAN(eps=10/6371e3, min_samples=1, metric="haversine").fit(np.radians(locations))
    return db.labels_

def verify_photos(file_paths: List[str]):
    """Verify photos for fraud detection using automatic location detection."""
    results = []
    locations = []
    depths = []
    timestamps = []
    devices = []

    # Process each photo
    for file_path in file_paths:
        try:
            # Initialize variables
            score = 1.0
            reasons = []
            has_location = False
            location_methods_tried = []
            location_confidence = 0.0  # Initialize location confidence
            
            # Extract metadata
            metadata = extract_exif_metadata(file_path)
            
            # Compute depth first as it doesn't depend on metadata
            depth = compute_depth(file_path)
            
            # Try all location detection methods in order of reliability
            
            # Method 1: Try EXIF GPS data
            if metadata["lat"] is not None and metadata["lon"] is not None:
                locations.append((metadata["lat"], metadata["lon"]))
                has_location = True
                location_methods_tried.append("EXIF GPS data")
                location_confidence = 0.9  # High confidence for EXIF data

            # Method 2: Try OCR to detect location from text
            if not has_location:
                try:
                    lat, lon, conf, location_text = detect_location_from_text(file_path)
                    if lat is not None and lon is not None:
                        metadata["lat"] = lat
                        metadata["lon"] = lon
                        locations.append((lat, lon))
                        has_location = True
                        location_methods_tried.append("Text detection")
                        location_confidence = conf
                except Exception as e:
                    print(f"OCR detection failed: {str(e)}")

            # Method 3: Try visual feature detection
            if not has_location:
                detected_lat, detected_lon = detect_location_from_image(file_path)
                if detected_lat is not None and detected_lon is not None:
                    metadata["lat"] = detected_lat
                    metadata["lon"] = detected_lon
                    locations.append((detected_lat, detected_lon))
                    has_location = True
                    location_methods_tried.append("Visual detection")
                    location_confidence = 0.5  # Lower confidence for ML detection
            
            # Update result based on location detection
            if has_location:
                reasons.append(f"Location detected using: {', '.join(location_methods_tried)}")
                # Adjust score based on detection method reliability
                if "EXIF GPS data" in location_methods_tried:
                    score *= 1.0  # Most reliable
                elif "Text detection" in location_methods_tried:
                    score *= 0.9  # Fairly reliable
                else:
                    score *= 0.8  # Visual detection is less precise
            else:
                reasons.append("Could not detect location from image")
                score *= 0.5  # Significant penalty for no location
                
            # Store data for later analysis
            if metadata["timestamp"]:
                timestamps.append(metadata["timestamp"])
            if metadata["device"]:
                devices.append(metadata["device"])

            # Analyze image authenticity
            authenticity_score, authenticity_reasons = analyze_image_authenticity(file_path)
            score *= authenticity_score
            reasons.extend(authenticity_reasons)

            # Create result
            result = {
                "file": os.path.basename(file_path),
                "status": None,  # Will be set later
                "score": score,
                "reason": reasons,
                "metadata": metadata,
                "depth": depth,
                "cluster": -1,  # Will be updated if geolocation exists
                "location_confidence": location_confidence,
                "location_method": "; ".join(location_methods_tried) if location_methods_tried else "None"
            }
            results.append(result)
            
        except Exception as e:
            # Handle file-level errors gracefully
            results.append({
                "file": os.path.basename(file_path),
                "status": "Error",
                "score": 0.0,
                "reason": [f"Processing error: {str(e)}"],
                "metadata": {"lat": None, "lon": None, "timestamp": None, "device": None},
                "depth": 0.0,
                "cluster": -1,
                "location_confidence": 0.0,
                "location_method": "None"
            })

    # Cluster geolocations if we have any
    if locations:
        clusters = cluster_geolocations(locations)
        loc_index = 0
        for result in results:
            if result["metadata"]["lat"] is not None and result["metadata"]["lon"] is not None:
                if loc_index < len(clusters):
                    result["cluster"] = int(clusters[loc_index])
                loc_index += 1

    # Final fraud analysis
    for i, result in enumerate(results):
        if "status" in result:
            continue
        
        cluster = result["cluster"]
        cluster_photos = [r for r in results if r["cluster"] == cluster]
        
        # Update reasons based on cluster analysis
        reasons = result["reason"]
        
        # Check for too many photos in same location
        if len(cluster_photos) > 2:
            result["score"] *= 0.6
            reasons.append("Excessive photos in same location cluster")

        # Check for similar depths in cluster
        for other in cluster_photos:
            if other["file"] != result["file"]:
                depth_diff = abs(result["depth"] - other["depth"])
                if depth_diff < 2.0:
                    result["score"] *= 0.7
                    reasons.append("Similar photo depth in cluster")

        # Check for suspicious timing
        for other in cluster_photos:
            if (other["file"] != result["file"] and 
                other["metadata"]["timestamp"] and result["metadata"]["timestamp"]):
                time_diff = abs((other["metadata"]["timestamp"] - 
                               result["metadata"]["timestamp"]).total_seconds())
                if time_diff < 15:
                    result["score"] *= 0.6
                    reasons.append("Photos taken too quickly")

        # Check for multiple submissions from same device
        same_device_count = sum(1 for r in cluster_photos 
                              if r["metadata"]["device"] == result["metadata"]["device"])
        if same_device_count > 2:
            result["score"] *= 0.7
            reasons.append("Multiple submissions from same device")

        # Set final status based on score
        result["score"] = max(0.0, min(1.0, result["score"]))  # Clamp between 0 and 1
        if result["score"] < 0.5:
            result["status"] = "Rejected"
        elif result["score"] < 0.7:
            result["status"] = "Suspicious"
        else:
            result["status"] = "Verified"

    return results


def detect_location_from_image(image_path: str) -> Tuple[float, float]:
    """Detect approximate location from image using multiple methods."""
    print(f"Attempting to detect location from image: {image_path}")
    
    # Method 1: Try OCR detection
    ocr_lat, ocr_lon, ocr_confidence, location_text = detect_location_from_text(image_path)
    
    if ocr_lat and ocr_lon and ocr_confidence > 0.7:
        return ocr_lat, ocr_lon
        
    # Method 2: Try visual feature detection
    try:
        init_scene_model()  # Initialize model if needed
        img = tf.keras.preprocessing.image.load_img(image_path, target_size=(224, 224))
        img_array = tf.keras.preprocessing.image.img_to_array(img)
        img_array = tf.expand_dims(img_array, 0)
        img_array = tf.keras.applications.efficientnet_v2.preprocess_input(img_array)
        
        predictions = scene_model.predict(img_array)
        detected_lat, detected_lon = predictions[0]
        
        # Validate predictions are within reasonable ranges
        if -90 <= detected_lat <= 90 and -180 <= detected_lon <= 180:
            return detected_lat, detected_lon
    except Exception as e:
        print(f"Visual detection error: {e}")
    
    return None, None
    try:
        # Load and preprocess image
        img = tf.keras.preprocessing.image.load_img(
            image_path, target_size=(224, 224)
        )
        img_array = tf.keras.preprocessing.image.img_to_array(img)
        img_array = tf.expand_dims(img_array, 0)
        img_array = tf.keras.applications.efficientnet_v2.preprocess_input(img_array)
        
        # Get visual features and predict location
        if scene_model is not None:
            predictions = scene_model.predict(img_array)
            lat, lon = predictions[0]
            
            # Use reverse geocoding to validate and refine location
            geolocator = Nominatim(user_agent="board_verification")
            location = geolocator.reverse((lat, lon), exactly_one=True)
            
            if location:
                return location.latitude, location.longitude
        
        return None, None
    except Exception as e:
        logging.error(f"Error detecting location from image: {e}")
        return None, None

# Initialize model variables
midas = None
transform = None

def init_midas():
    """Initialize MiDaS model lazily on first use"""
    global midas, transform
    if midas is None:
        try:
            midas = torch.hub.load("intel-isl/MiDaS", "MiDaS_small")
            midas.eval()
            transform = torch.hub.load("intel-isl/MiDaS", "transforms").small_transform
        except Exception as e:
            print(f"Error loading MiDaS model: {str(e)}")
            raise

def extract_exif_metadata(image_path: str):
    """Extract geolocation, timestamp, and device from EXIF."""
    try:
        with open(image_path, "rb") as img_file:
            img = ExifImage(img_file)
            lat = img.get("gps_latitude", None)
            lon = img.get("gps_longitude", None)
            timestamp = img.get("datetime", None)
            device = img.get("model", None)
            if lat and lon:
                lat = float(lat[0]) + lat[1]/60 + lat[2]/3600
                lon = float(lon[0]) + lon[1]/60 + lon[2]/3600
            if timestamp:
                timestamp = datetime.strptime(timestamp, "%Y:%m:%d %H:%M:%S")
            return {"lat": lat, "lon": lon, "timestamp": timestamp, "device": device}
    except:
        return {"lat": None, "lon": None, "timestamp": None, "device": None}

def compute_depth(image_path: str):
    """Estimate camera-to-board distance using MiDaS."""
    try:
        # Initialize model if needed
        if midas is None:
            init_midas()
            
        img = cv2.imread(image_path)
        if img is None:
            raise ValueError("Unable to read image")
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        input_batch = transform(img).unsqueeze(0)
        with torch.no_grad():
            depth = midas(input_batch)
            depth = torch.nn.functional.interpolate(
                depth.unsqueeze(1), size=img.shape[:2], mode="bicubic"
            ).squeeze()
        return float(depth.mean().item())
    except Exception as e:
        print(f"Error computing depth: {str(e)}")
        # On failure return a safe default depth and let higher-level logic
        # penalize but not crash the whole request
        return 0.0

def verify_photos(file_paths: List[str]):
    """Verify photos for fraud detection using automatic location detection.
    
    Args:
        file_paths: List of paths to photos
    """
    results = []
    locations = []
    depths = []
    timestamps = []
    devices = []

    # Process each photo
    for file_path in file_paths:
        try:
            reasons = []
            score = 1.0
            
            # Extract metadata
            metadata = extract_exif_metadata(file_path)
            
            # Compute depth first as it doesn't depend on metadata
            depth = compute_depth(file_path)
            
            # Extract and validate location information
            has_location = False
            location_methods_tried = []

            # Initialize location tracking
            has_location = False
            location_methods_tried = []
            
            # Method 1: Try EXIF GPS data
            if metadata["lat"] is not None and metadata["lon"] is not None:
                locations.append((metadata["lat"], metadata["lon"]))
                has_location = True
                location_methods_tried.append("EXIF GPS data")
                location_confidence = 1.0  # Highest confidence for EXIF data

            # Method 2: Try OCR to detect location from text in image
            if not has_location:
                try:
                    lat, lon, conf, location_text = detect_location_from_text(file_path)
                    if lat is not None and lon is not None:
                        metadata["lat"] = lat
                        metadata["lon"] = lon
                        locations.append((lat, lon))
                        has_location = True
                        location_methods_tried.append("Text detection")
                except Exception as e:
                    print(f"OCR detection failed: {str(e)}")

            # Method 3: Try visual feature detection
            if not has_location:
                detected_lat, detected_lon = detect_location_from_image(file_path)
                if detected_lat is not None and detected_lon is not None:
                    metadata["lat"] = detected_lat
                    metadata["lon"] = detected_lon
                    locations.append((detected_lat, detected_lon))
                    has_location = True
                    location_methods_tried.append("Visual detection")
            
            # Update result based on location detection
            if has_location:
                reasons.append(f"Location detected using: {', '.join(location_methods_tried)}")
                # Adjust score based on detection method reliability
                if "EXIF GPS data" in location_methods_tried:
                    score *= 1.0  # Most reliable
                elif "Text detection" in location_methods_tried:
                    score *= 0.9  # Fairly reliable
                else:
                    score *= 0.8  # Visual detection is less precise
            else:
                reasons.append("Could not detect location from image")
                score *= 0.5  # Significant penalty for no location
                
            # Store data
            if metadata["timestamp"]:
                timestamps.append(metadata["timestamp"])
            if metadata["device"]:
                devices.append(metadata["device"])
                
            # Create initial result
            result = {
                "file": os.path.basename(file_path),
                "status": None,  # Will be set later
                "score": score,  # This is the authenticity score
                "reason": reasons,
                "metadata": metadata,
                "depth": depth,
                "cluster": -1,  # Will be updated if geolocation exists
                "location_confidence": location_confidence
            }
            results.append(result)
        except Exception as e:
            # Capture file-level errors as a result entry so one bad image
            # doesn't cause a 500 for the whole request.
            results.append({
                "file": os.path.basename(file_path),
                "status": "Error",
                "score": 0.0,
                "reason": [f"Processing error: {str(e)}"],
                "metadata": {"lat": None, "lon": None, "timestamp": None, "device": None},
                "depth": 0.0,
                "cluster": -1,
                "location_confidence": 0.0
            })

    # Cluster geolocations if we have any
    if locations:
        clusters = cluster_geolocations(locations)
        loc_index = 0
        for result in results:
            if result["metadata"]["lat"] is not None and result["metadata"]["lon"] is not None:
                if loc_index < len(clusters):
                    result["cluster"] = int(clusters[loc_index])
                loc_index += 1

    # Fraud detection
    for i, result in enumerate(results):
        if "status" in result:
            continue
        score = 1.0
        reason = []

        # Object Detection (mock; replace with YOLOv9)
        score *= 0.9
        # Manipulation Check (mock; replace with XceptionNet)
        score *= 0.95
        # Background Check (mock; replace with ResNet-18)
        score *= 0.95

        # Spatial Analysis
        cluster = result["cluster"]
        cluster_photos = [r for r in results if r["cluster"] == cluster]
        if len(cluster_photos) > 2:
            score *= 0.6
            reason.append("Excessive photos in 10m cluster")

        # Depth check
        for other in cluster_photos:
            if other["file"] != result["file"]:
                depth_diff = abs(result["depth"] - other["depth"])
                if depth_diff < 2.0:
                    score *= 0.7
                    reason.append("Similar depth in cluster")

        # Temporal check
        for other in cluster_photos:
            if other["file"] != result["file"] and other["metadata"]["timestamp"] and result["metadata"]["timestamp"]:
                time_diff = abs((other["metadata"]["timestamp"] - result["metadata"]["timestamp"]).total_seconds())
                if time_diff < 15:
                    score *= 0.6
                    reason.append("Photos taken too quickly")

        # Device check
        if sum(1 for r in cluster_photos if r["metadata"]["device"] == result["metadata"]["device"]) > 2:
            score *= 0.7
            reason.append("Multiple submissions from same device")

        # Image analysis
        try:
            img = Image.open(file_paths[i])
            # Check image quality
            if img.size[0] < 800 or img.size[1] < 800:
                score *= 0.8
                reason.append("Low resolution image")
            # Check if image was edited
            if "Software" in img.info:
                score *= 0.7
                reason.append("Image edited with software")
        except Exception as e:
            score *= 0.5
            reason.append("Error analyzing image")

        # Calculate location confidence based on methods used
        location_confidence = 0.0
        if has_location:
            if "EXIF GPS data" in location_methods_tried:
                location_confidence = 1.0
            elif "Text detection" in location_methods_tried:
                location_confidence = 0.7
            elif "Visual detection" in location_methods_tried:
                location_confidence = 0.5

        # Final verdict
        result["score"] = score
        result["location_confidence"] = location_confidence
        if score > 0.7:  # Lowered threshold since geo might be missing
            result["status"] = "Real"
        elif score > 0.4:
            result["status"] = "Review"
        else:
            result["status"] = "Fake"
        result["reason"] = reason if reason else ["Passed"]

    # Generate map for photos with locations
    map_url = None
    if locations:
        m = folium.Map(location=[locations[0][0], locations[0][1]], zoom_start=15)
        loc_index = 0
        for result in results:
            if result["metadata"]["lat"] is not None and result["metadata"]["lon"] is not None:
                folium.Marker(
                    [result["metadata"]["lat"], result["metadata"]["lon"]], 
                    popup=f"{result['status']}: {', '.join(result['reason'])}"
                ).add_to(m)
                loc_index += 1
        map_url = "static/map.html"
        m.save(map_url)

    return results, map_url